{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yf0EQLcZFU_b",
    "outputId": "c765165d-1136-4b47-a9d4-14c93b7118d7"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.initializers import Constant\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(device=gpus[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "! git config --global credential.helper store\n",
    "hf_token='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'\n",
    "login(token=hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OmEHY8JxFbVV",
    "outputId": "6bd96470-e2f7-4f62-821c-00635549e109"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('clean-HARD.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5T5jmHvMhfd4"
   },
   "outputs": [],
   "source": [
    "data.sentences=data.sentences.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KiLX3eBDGkC9",
    "outputId": "1bebabff-12ff-4fec-99c1-7837299674cb"
   },
   "outputs": [],
   "source": [
    "sequence_length = 512\n",
    "max_features = 20000 # this is the number of words we care about \n",
    "\n",
    "#fit the tokenizer onto the text.\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ', oov_token='<unw>', filters=' ')\n",
    "tokenizer.fit_on_texts(data['sentences'].values)\n",
    "\n",
    "# this takes our sentences and replaces each word with an integer\n",
    "X = tokenizer.texts_to_sequences(data['sentences'].values)\n",
    "\n",
    "# we then pad the sequences so they're all the same length (sequence_length)\n",
    "X = pad_sequences(X, sequence_length)\n",
    "\n",
    "y = pd.get_dummies(data['rating']).values\n",
    "\n",
    "# lets keep  back 20% of the data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)  \n",
    "\n",
    "print(\"test set size \" + str(len(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdYl0VBB5ILS",
    "outputId": "b4bc98d3-e06a-4465-96df-283112e84703"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "f = open('GloVe-Arabic/vectorsHARD.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:] ,dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmuunyzE5mUr",
    "outputId": "95d44e7f-8e1f-45e0-e856-b38cf5bcf872"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lrdf-TuV7aqw",
    "outputId": "007df683-f9b7-4e3d-dd8b-c758fd861e98"
   },
   "outputs": [],
   "source": [
    "num_words = min(max_features, len(word_index)) + 1\n",
    "print(num_words)\n",
    "\n",
    "embedding_dim =200\n",
    "\n",
    "# first create a matrix of zeros, this is our embedding matrix\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "# for each word in out tokenizer lets try to find that work in our w2v model\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # we found the word - add that words vector to the matrix\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # doesn't exist, assign a random vector\n",
    "        embedding_matrix[i] = np.random.randn(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FwDEau9q8dc1",
    "outputId": "c3c464c7-b424-4d36-a9f8-f243a11481da"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(num_words,\n",
    "                             embedding_dim,\n",
    "                             embeddings_initializer=Constant(embedding_matrix),\n",
    "                             input_length=sequence_length,\n",
    "                             trainable=False),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(units=4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FwDEau9q8dc1",
    "outputId": "c3c464c7-b424-4d36-a9f8-f243a11481da"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"biLSTMhard.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=90,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQl0_SBn8oHp",
    "outputId": "5547b2a0-f7f6-4882-e416-9b4d3c027c23"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=batch_size, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sf2pQY4Q9ibc",
    "outputId": "4cd7ba7f-9599-422e-da9c-22208cdb93ed"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XG-J1z2d02oU",
    "outputId": "69ef2456-59d5-4e21-9132-ea415d62958f"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"biLSTMhard.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_keras('biLSTMhard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizerbiLSTMhard.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import push_to_hub_keras\n",
    "push_to_hub_keras(model, 'biLSTMhard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import from_pretrained_keras\n",
    "\n",
    "model_hf = from_pretrained_keras('NorahAlshahrani/biLSTMhard')\n",
    "model_hf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# loaded_model = tf.keras.models.load_model(\"biLSTMhard.h5\")\n",
    "tokenizer = pickle.load(open('tokenizerbiLSTMhard.pickle', 'rb'))\n",
    "\n",
    "text = \"أنا لا أحب قراءة الكتب\"\n",
    "token = tokenizer.texts_to_sequences([text])\n",
    "token = pad_sequences(token, maxlen=512)\n",
    "\n",
    "outputs=model_hf.predict(token)\n",
    "outputs = torch.from_numpy(outputs)\n",
    "\n",
    "id2label = {\n",
    " 0: 'Negative',\n",
    " 1: 'Negative',\n",
    " 2: 'Positive',\n",
    " 3: 'Positive'\n",
    "}\n",
    "\n",
    "predClassID= outputs.argmax().item()\n",
    "pred = outputs.softmax(dim=-1).tolist()\n",
    "pred = round(np.max(pred)*100, 2)\n",
    "\n",
    "print(f\"Text: '{text}' \\nLabel: {id2label[predClassID]} \\nPredication: {pred}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
